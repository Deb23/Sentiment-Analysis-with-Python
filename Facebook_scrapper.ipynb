{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 25 comments\n",
      "got 50 comments\n",
      "got 75 comments\n",
      "got 100 comments\n",
      "got 125 comments\n",
      "got 150 comments\n",
      "got 175 comments\n",
      "got 200 comments\n",
      "got 225 comments\n",
      "got 250 comments\n",
      "got 275 comments\n",
      "got 300 comments\n",
      "got 325 comments\n",
      "got 350 comments\n",
      "got 375 comments\n",
      "got 400 comments\n",
      "got 425 comments\n",
      "got 450 comments\n",
      "got 475 comments\n",
      "got 500 comments\n",
      "got 525 comments\n",
      "got 550 comments\n",
      "got 575 comments\n",
      "got 600 comments\n",
      "got 625 comments\n",
      "got 650 comments\n",
      "got 675 comments\n",
      "got 700 comments\n",
      "got 725 comments\n",
      "got 750 comments\n",
      "got 775 comments\n",
      "got 800 comments\n",
      "got 825 comments\n",
      "got 850 comments\n",
      "got 875 comments\n",
      "got 900 comments\n",
      "got 925 comments\n",
      "got 950 comments\n",
      "got 975 comments\n",
      "got 1000 comments\n",
      "train on 2000 instances, test on 1000 instances\n",
      "accuracy: 0.929\n",
      "Most Informative Features\n",
      "                  avoids = True              pos : neg    =     13.0 : 1.0\n",
      "              astounding = True              pos : neg    =     12.3 : 1.0\n",
      "                    slip = True              pos : neg    =     11.7 : 1.0\n",
      "             outstanding = True              pos : neg    =     11.5 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.0 : 1.0\n",
      "               insulting = True              neg : pos    =     11.0 : 1.0\n",
      "             fascination = True              pos : neg    =     11.0 : 1.0\n",
      "                    3000 = True              neg : pos    =     11.0 : 1.0\n",
      "                   sucks = True              neg : pos    =     10.6 : 1.0\n",
      "                thematic = True              pos : neg    =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "def extract_fb_comments():\n",
    "        # You will need to update the user token used here\n",
    "        token = 'EAACEdEose0cBAJxVRQoECuXRWIaHKCHAfCivQmvUR2FIx1KQnwvMrCnYZAmriR0V0wL96jk4T8h5xUh7lULznQHvQux7tG6gVqWpxFrmooxgRDePFYyDID90JL9D0BUTYycTIgZCRxtPHyYBJlewgss5EOUTjmUq5vg22mOvBENWlRz3rqCIqJIJrZB6MXiOg1TbDWhQgZDZD'\n",
    "        response = requests.get(\"https://graph.facebook.com/153080620724_10160428186555725/comments?access_token=\"+token)\n",
    "        data = []\n",
    "        while True:\n",
    "            json_data = response.json()\n",
    "            \n",
    "            # catch errors returned by the Graph API\n",
    "            if 'error' in json_data:\n",
    "                raise Exception(json_data['error']['message'])\n",
    "            \n",
    "            #create a list d of all the comments\n",
    "            for comment in json_data['data']:\n",
    "                    data.append(comment['message'].replace('\\n', ' '))\n",
    "            \n",
    "            # print the number of comments extracted from one page of response\n",
    "            print('got {} comments'.format(len(data)))\n",
    "            \n",
    "            # limit the number of comments extracted to 1000           \n",
    "            if(len(data)==1000):\n",
    "                break\n",
    "            else:   \n",
    "                # check if there are more comments\n",
    "                if 'paging' in json_data and 'next' in json_data['paging']:\n",
    "                    response = requests.get(json_data['paging']['next'])\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        # convert the list d into a dataframe\n",
    "        return data\n",
    "\n",
    "# Bag of Words feature extraction since all NLTK classifiers work on a dictionary of {Bag_of_words,sentiment}\n",
    "def word_feats(words):\n",
    "        return dict([(word, True) for word in words])\n",
    "\n",
    "#We will be using the movie review corpus of NLTK to train our classifier. \n",
    "#Even though this isn't the best way to train our classifier to analyze sentiment on much shorter facebook comments\n",
    "\n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "# Converting the movie reviews into a dictionary of {Bag_of_words,sentiment} to create our training dataset\n",
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "trainfeats = negfeats + posfeats\n",
    "\n",
    "# Converting our comments collected in the list data[] into a dictionary of {Bag_of_words,sentiment} to create our test dataset\n",
    "data = extract_fb_comments()\n",
    "testfeats = [(word_feats(comment),'neg') for comment in data]\n",
    "\n",
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    "\n",
    "# Run Naive Bayes Classifier on training dataset and test its accuracy with the test dataset\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "\n",
    "# Print the most important features identified from the test dataset\n",
    "classifier.show_most_informative_features()\n",
    "\n",
    "                                 \n",
    "\n",
    "                    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
